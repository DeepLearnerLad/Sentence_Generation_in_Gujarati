{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrRpX0GBk9zt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fjv66k7xlQzI",
        "outputId": "60803abf-16ed-499a-b570-38f08e0b4b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read, then decode for single file.\n",
        "path_to_file = '/content/drive/MyDrive/data2/data5.txt'\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')\n",
        "\n",
        "# #Read, then decode for multiple files\n",
        "# story_path = r\"/content/drive/MyDrive/data2/\"\n",
        "\n",
        "# def read_all_stories(story_path):\n",
        "#     txt = []\n",
        "#     for _, _, files in os.walk(story_path):\n",
        "#         for file in files:\n",
        "#             with open(os.path.join(story_path, file), encoding='utf-8') as f:\n",
        "#                 for line in f:\n",
        "#                     line = line.strip()\n",
        "#                     if line == '----------':\n",
        "#                         break\n",
        "#                     if line != '':\n",
        "#                         txt.append(line)\n",
        "#     return txt\n",
        "\n",
        "# text = read_all_stories(story_path)\n",
        "# print(\"number of lines = \", len(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KNWgy6PlUgZ",
        "outputId": "c3af23ca-bc4d-467f-91ed-4ef19f991726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 20702 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "# # Load your Gujarati text dataset (replace 'data.txt' with your dataset file)\n",
        "# with open(path_to_file, 'r', encoding='utf-8') as file:\n",
        "#     text = file.read()\n",
        "\n",
        "# Split the text into sentences (assuming one sentence per line)\n",
        "sentences = text.split('\\n')\n",
        "# sentences = text\n",
        "# Tokenize and pad the sentences\n",
        "max_words = 1000000  # Maximum number of words to keep in the vocabulary\n",
        "max_sequence_length = 10  # Maximum sequence length for padding\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "vsbHC35rlf41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = padded_sequences[:, :-1]\n",
        "y = padded_sequences[:, 1:]"
      ],
      "metadata": {
        "id": "nKFZxM8Qlliu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_sequence_length-1))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dense(max_words, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "c26aua-Flpbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "KL0qNOBul5wF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(x, y, epochs=10, batch_size=8)\n",
        "# model.save('/content/drive/MyDrive/LSTM(D3)', save_format='tf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4r2nzLDXlsWY",
        "outputId": "b4127261-9ac8-4e56-fa18-5f1ac12eb76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "29/29 [==============================] - 11s 269ms/step - loss: 13.5172 - accuracy: 0.5068\n",
            "Epoch 2/10\n",
            "29/29 [==============================] - 7s 242ms/step - loss: 9.9576 - accuracy: 0.5283\n",
            "Epoch 3/10\n",
            "29/29 [==============================] - 6s 192ms/step - loss: 5.5603 - accuracy: 0.5283\n",
            "Epoch 4/10\n",
            "29/29 [==============================] - 6s 213ms/step - loss: 4.4446 - accuracy: 0.5283\n",
            "Epoch 5/10\n",
            "29/29 [==============================] - 6s 198ms/step - loss: 4.0496 - accuracy: 0.5283\n",
            "Epoch 6/10\n",
            "29/29 [==============================] - 5s 187ms/step - loss: 3.8675 - accuracy: 0.5283\n",
            "Epoch 7/10\n",
            "29/29 [==============================] - 6s 196ms/step - loss: 3.7743 - accuracy: 0.5283\n",
            "Epoch 8/10\n",
            "29/29 [==============================] - 5s 183ms/step - loss: 3.7060 - accuracy: 0.5283\n",
            "Epoch 9/10\n",
            "29/29 [==============================] - 6s 188ms/step - loss: 3.6631 - accuracy: 0.5283\n",
            "Epoch 10/10\n",
            "29/29 [==============================] - 5s 178ms/step - loss: 3.6277 - accuracy: 0.5283\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x795c2bf47ee0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate sentences\n",
        "seed_text = \"પેલું તોફાની ઘેટું ઘણી વાર રાજાના રસોડામાં ઘૂસી જાય\"\n",
        "seed_sequence = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\n",
        "generated_sequence = seed_sequence\n",
        "print(seed_sequence)\n",
        "for _ in range(5):  # Generate 20 words/symbols\n",
        "    next_word_probs = model.predict(np.array([generated_sequence]))[0][-1]\n",
        "    sampled_word_index = np.random.choice(len(next_word_probs), p=next_word_probs)\n",
        "    generated_sequence.append(sampled_word_index)\n"
      ],
      "metadata": {
        "id": "fZchqFRCl0lK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abdb52f6-3946-4f2e-9f38-99b30846ef2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1039, 203, 103, 963, 134, 126, 294, 159, 90]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the generated sequence back to text\n",
        "generated_text = ' '.join([tokenizer.index_word.get(idx, '') for idx in generated_sequence if idx != 0])\n",
        "\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff6-MFEyrGtu",
        "outputId": "1c45f317-6b94-48f1-bad4-251eef2b54ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "પેલું તોફાની ઘેટું ઘણી વાર રાજાના રસોડામાં ઘૂસી જાય એક ‘હવે શિકારી\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U2FuzRHXrlGs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}